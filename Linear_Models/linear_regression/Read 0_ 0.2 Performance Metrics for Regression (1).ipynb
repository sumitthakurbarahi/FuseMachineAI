{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NWzgmbY-aitB"},"source":["# Linear Regression - Performance Metrics\n","\n","It is common to build several different linear regression models using different features when attempting to predict a response. In the case of a single feature, it is sometimes possible to look at the models and determine which is better. However, in many situations, it is not possible to visually determine which model is best, especially in the case of multiple linear regression. To select the best model, we need to evaluate our models and select the one with the least amount of error when predicting the output.\n","  \n","**Error Function:**\n","\n","<figure align=\"center\">\n","<!-- <img src=\"https://drive.google.com/uc?id=1T609cjRRLk4-ANWq1sePDF__WdfG99uY\" height=\"500px\", width=\"600px\">  -->\n","<img src=\"https://i.postimg.cc/qvbPf4ty/image.png\" height=500px>\n","</figure>\n","\n","An error function represents the difference between the actual and predicted values; the higher the error value, the worse the model. When performing linear regression, you obtain a line of best fit as shown by the red line in the figure above. Points that lie on the line will be predicted correctly. However, as you can see from the figure above, many points can lie away from the regression line.\n","\n","A residual is the difference between the actual response variable $y_{i}$ and the predicted outcome $\\hat{y_{i}}$, and is given by $y_{i}-\\hat{y_{i}}$. The residuals can be thought of as the error that is unexplained by the regression line. A residual can be positive or negative, denoted by $r_{+}$, and $r_{-}$ respectively. The residual sum of squares (RSS) is one of several error measures used in linear regression.\n","\n","**Residual Sum of Squares (RSS):**\n","\n","$$ \\text{RSS} = \\sum_{i=1}^{m} (y_{i} - \\hat{y_{i}})^{2} $$\n","\n","One issue with the residual sum of squares is that it does not account for the number of samples used when calculating the error; if we double the number of samples, the RSS will increase significantly. One way to address this is to divide the RSS by the number of sample points. This is referred to as the mean squared error (MSE).\n","\n","**Mean Squared Error (MSE):**\n","\n","$$ \\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n} (y_{i} - \\hat{y_{i}})^{2} $$\n","\n","There are times when large errors are particularly undesirable. By taking the square root of the MSE, larger errors are penalized more than smaller errors. This error measurement is referred to as the root mean squared error (RMSE).\n","\n","**Root Mean Squared Error (RMSE):**\n","\n","$$ \\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - \\hat{y_{i}})^{2}} $$\n","\n","The previous three error measures mentioned are sensitive to the presence of outliers. In the presence of outliers, one may want to consider the mean absolute error, which is the average of the absolute values of the residuals.\n","\n","**Mean Absolute Error (MAE):**\n","\n","$$ \\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n}|y_{i} - \\hat{y_{i}}|$$"]},{"cell_type":"markdown","metadata":{"id":"WHZv8DJEqTRV"},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{"id":"dchRbce5beqJ"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"JdeM1DYUbeqL"},"source":["import numpy as np\n","import pandas as pd\n","from IPython.display import display, HTML"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oY-w04oIbeqY"},"source":["### Load Dataset"]},{"cell_type":"code","metadata":{"id":"kjdTy3M0beqa","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1592813151067,"user_tz":-345,"elapsed":1938,"user":{"displayName":"Rojesh Man Shikhrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8acfmaw1GQlpTZ5omp8F9rjlgt0qiN-4EMGo8=s64","userId":"17287545535191686920"}},"outputId":"33d975cb-3859-4a47-e519-87da82ddada6"},"source":["data_path = \"https://www.statlearning.com/s/Advertising.csv\"\n","\n","# Read the CSV data from the link\n","data_df = pd.read_csv(data_path,index_col=0)\n","\n","# Print out first 5 samples from the DataFrame\n","data_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TV</th>\n","      <th>radio</th>\n","      <th>newspaper</th>\n","      <th>sales</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>230.1</td>\n","      <td>37.8</td>\n","      <td>69.2</td>\n","      <td>22.1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>44.5</td>\n","      <td>39.3</td>\n","      <td>45.1</td>\n","      <td>10.4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>17.2</td>\n","      <td>45.9</td>\n","      <td>69.3</td>\n","      <td>9.3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>151.5</td>\n","      <td>41.3</td>\n","      <td>58.5</td>\n","      <td>18.5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>180.8</td>\n","      <td>10.8</td>\n","      <td>58.4</td>\n","      <td>12.9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      TV  radio  newspaper  sales\n","1  230.1   37.8       69.2   22.1\n","2   44.5   39.3       45.1   10.4\n","3   17.2   45.9       69.3    9.3\n","4  151.5   41.3       58.5   18.5\n","5  180.8   10.8       58.4   12.9"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"-Z7-rlACaitC"},"source":["### Scikit-Learn's Error Metrics\n","\n","Scikit-Learn's [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) package has several metrics for [regression](https://scikit-learn.org/stable/modules/classes.html#regression-metrics).\n","\n","* **Residual Sum of Squares (RSS):**\n","\n","  Scikit-Learn does not provide a directed implementation to calculate the RSS. However, since the MSE is equal to the RSS divided by the number of samples, we can use the [`mean_squared_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) function times the number of samples to obtain the RSS.\n","\n","\n","* **Mean Squared Error (MSE):**\n","\n","  The [`mean_squared_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) function implements the MSE.\n","\n","\n","* **Root Mean Squared Error (RMSE):**\n","\n","  Again, Scikit-Learn does not directly implement the RMSE, but it can be achieved by taking the square root of the MSE.\n","\n","\n","* **Mean Absolute Error (MAE):**\n","\n","  The [`mean_absolute_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error) function implements the MSE.\n","\n","We are going to calculate and analyze these performance metrics on the advertising dataset. This dataset was introduced in the previous notebook where we build simple and multiple linear regression models."]},{"cell_type":"code","metadata":{"id":"Iks5e5xgaitO"},"source":["# Import LinearRegression and necessary evaluation metrics from sklearn\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score\n","\n","# Create a dictionary of lists for storing the values of all evaluation metrics\n","results = {\n","    \"Residual Sum of Squares\":list(),\n","    \"Mean Squared Error\":list(),\n","    \"Root Mean Squared Error\":list(),\n","    \"Mean Absolute Error\":list(),\n","}\n","\n","\n","# Train a linear regression model\n","def train_lr(X,y_true):\n","    linear_regression = LinearRegression()\n","    linear_regression.fit(X,y_true)\n","    y_pred = linear_regression.predict(X)\n","\n","    # Evaluate different metrics\n","    results[\"Residual Sum of Squares\"].append( len(y_true) * mean_squared_error(y_true, y_pred) )\n","    results[\"Mean Squared Error\"].append( mean_squared_error(y_true, y_pred) )\n","    results[\"Root Mean Squared Error\"].append( np.sqrt(mean_squared_error(y_true, y_pred)) )\n","    results[\"Mean Absolute Error\"].append( median_absolute_error(y_true, y_pred) )\n","\n","\n","\n","# Train and analyze performance metric over each of the following feature groups\n","feature_list = [\"TV\",\n","                \"radio\",\n","                \"newspaper\",\n","                \"TV, radio\",\n","                \"TV, radio, newspaper\"]\n","\n","# Train the combination of features in feature_list\n","for features in feature_list:\n","    feature =  features.split(\", \")\n","    train_lr(data_df[feature], data_df[[\"sales\"]])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hVlY08CnaitR"},"source":["### Performance Results\n","\n","For the three simple linear regression models, the various error values show that the TV model is probably the best. This matches our intuition obtained from viewing the scatter plots.\n","\n","Furthermore, the multiple linear regression model that uses the TV and radio features seems to perform better than the three simple linear regression models. This again matches our intuition that each of the advertising mediums alone is probably not enough to account for the sales.\n","\n","Observe that the model that uses the TV, radio, and newspaper features seems to be the best as it has the lowest error metrics. This is most likely due to overfitting (a topic which we will cover in later units), which might have been caused by the newspaper feature; recall that the newspaper feature seemed to be independent of our target variable, sales."]},{"cell_type":"code","metadata":{"id":"GeX3GGaEaitR","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1592813151071,"user_tz":-345,"elapsed":1901,"user":{"displayName":"Rojesh Man Shikhrakar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8acfmaw1GQlpTZ5omp8F9rjlgt0qiN-4EMGo8=s64","userId":"17287545535191686920"}},"outputId":"794f5d2f-34c7-4e2c-d61c-c3a8f93a1645"},"source":["feature_list = [\"TV\", \"radio\", \"newspaper\", \"TV + radio\", \"TV + radio + newspaper\"]\n","error_df = pd.DataFrame(results, index=feature_list).transpose()\n","display(error_df)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TV</th>\n","      <th>radio</th>\n","      <th>newspaper</th>\n","      <th>TV + radio</th>\n","      <th>TV + radio + newspaper</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Residual Sum of Squares</th>\n","      <td>2102.530583</td>\n","      <td>3618.479549</td>\n","      <td>5134.804544</td>\n","      <td>556.913980</td>\n","      <td>556.825263</td>\n","    </tr>\n","    <tr>\n","      <th>Mean Squared Error</th>\n","      <td>10.512653</td>\n","      <td>18.092398</td>\n","      <td>25.674023</td>\n","      <td>2.784570</td>\n","      <td>2.784126</td>\n","    </tr>\n","    <tr>\n","      <th>Root Mean Squared Error</th>\n","      <td>3.242322</td>\n","      <td>4.253516</td>\n","      <td>5.066954</td>\n","      <td>1.668703</td>\n","      <td>1.668570</td>\n","    </tr>\n","    <tr>\n","      <th>Mean Absolute Error</th>\n","      <td>2.026365</td>\n","      <td>2.614170</td>\n","      <td>3.440421</td>\n","      <td>1.079819</td>\n","      <td>1.075512</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                  TV  ...  TV + radio + newspaper\n","Residual Sum of Squares  2102.530583  ...              556.825263\n","Mean Squared Error         10.512653  ...                2.784126\n","Root Mean Squared Error     3.242322  ...                1.668570\n","Mean Absolute Error         2.026365  ...                1.075512\n","\n","[4 rows x 5 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"oal8maj1wjQF"},"source":["## Additional Resources:\n","\n","* Articles\n","\n"," - [Why squared error? ](https://www.benkuhn.net/squared/)\n"]}]}